{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa07198-0312-41ac-b820-debbc6d7fb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a5b43a-53d5-4961-b55f-b5baa3d895b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 1) What is Simple Linear Regression?\n",
    ">> a statistical method to model the relationship between one independent (predictor) variable and one dependent (outcome) variable,\n",
    "    assuming this relationship can be represented by a straight line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb32f6d-41ef-4937-a4ce-88bcf5a727a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 2) What are the key assumptions of Simple Linear Regression?\n",
    ">> a linear relationship between variables, independence of observations (no autocorrelation), homoscedasticity\n",
    "    (constant variance of errors), and normality of residuals(errors are normally distributed). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d7340c-6694-468b-b942-91ded7c13010",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 3) What does the coefficient m represent in the equation Y=mX+c?\n",
    ">> represents the slope (or gradient) of the straight line, indicating its steepness and direction (upward/downward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37098fb-0ee4-4d5b-b090-e0f5bd3b3baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 4) What does the intercept c represent in the equation Y=mX+c?\n",
    ">> y-intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac36eb5-e26c-4d5b-863e-d53c43f369d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 5) How do we calculate the slope m in Simple Linear Regression?\n",
    ">> \\(m=\\frac{n(\\sum xy)-(\\sum x)(\\sum y)}{n(\\sum x^{2})-(\\sum x)^{2}}\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c120096-3c36-4cc5-bbd8-ed1bb15296be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 6) What is the purpose of the least squares method in Simple Linear Regression?\n",
    ">> to find the best-fit straight line (regression line) for a set of data points by minimizing the sum of the squared vertical distances (residuals)\n",
    "     between the actual observed data points and the points predicted by the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c9d49f-782c-4632-baf5-0a08b285fce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 7) How is the coefficient of determination (R²) interpreted in Simple Linear Regression?\n",
    ">>  the proportion of the variance in the dependent variable that is predictable from the independent variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f5b92-f3e6-4279-8e4a-aab1960c89fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 8) What is Multiple Linear Regression?\n",
    ">> is a statistical method to predict a single dependent variable (outcome) using the values of two or more independent (predictor) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4967e50b-8e24-40fd-808f-78278daff93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 9) What is the main difference between Simple and Multiple Linear Regression?\n",
    ">> Simple Linear Regression models the relationship between one dependent variable and a single independent variable, \n",
    "    while Multiple Linear Regression model the relationship between one dependent variable and two or more independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7434568-d2e8-4b15-b52d-351f84e4f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 10) What are the key assumptions of Multiple Linear Regression?\n",
    ">> Linearity (straight-line relationship between predictors and response), Independence(observations and errors are unrelated),  Homoscedasticity \n",
    "    (constant variance of errors), No Multicollinearity (predictors aren't too correlated),  and Normality of Residuals (errors are normally distributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278ccf37-4733-4142-8ec8-14b6cd599b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 11) What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
    ">> the error (residual) variance isn't constant in a regression model, violating a key assumption of Ordinary Least Squares (OLS). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15c82ba-31a0-4db3-a38a-c49959b88cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 12) How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
    ">>  through variable management, using regularization techniques, or applying dimensionality reduction methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab27444-9fba-41a1-8a6b-ba5b7fc640a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 13) What are some common techniques for transforming categorical variable?\n",
    ">> encoding them into numerical formats like One-Hot Encoding (creating binary columns per category, best for nominal data)\n",
    "    or Label/Ordinal Encoding (assigning integers, suitable for ordered data like 'Small', 'Medium', 'Large').                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7ddac-1430-461b-80d0-498bd587306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 14) What is the role of interaction terms in Multiple Linear Regression?\n",
    ">> capture situations where the effect of one independent variable on the dependent variable changes depending on the level\n",
    "    of another independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e1763-3032-4573-9282-ba316a36f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 15) How can the interpretation of intercept differ between Simple and Multiple Linear Regression\n",
    ">> reflects how other variables influence the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b021e855-ecee-432f-bd9a-0cff7a3cf724",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 16) What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
    ">> indicating the strength and direction (positive or negative) of the relationship, directly affecting predictions by defining the steepness \n",
    "     and trend of the best-fit line, allowing us to estimate y-values for given x-values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26be1c4f-5d83-43cb-986c-324e456cb211",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 17) What are the limitations of using R² as a sole measure of model performance?\n",
    ">> it always increases with added variables (leading to overfitting), doesn't indicate if the model is biased or adequate \n",
    "    (a good model can have low R², a bad one high R²), fails for non-linear relationships, and confuses correlation with causation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecac16d-af1a-4705-80e1-632884b614e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 18) How would you interpret a large standard error for a regression coefficient\n",
    ">> A large standard error (SE) for a regression coefficient means high uncertainty and low precision in the estimate, indicating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e3ce87-c73b-48c4-86f5-c30eafdc0248",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 19) What is polynomial regression?\n",
    ">>  models non-linear relationships between variables by fitting a curve (a polynomial function) to data, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc29597-e087-43a4-896f-08269c785e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 20) When is polynomial regression used\n",
    ">>  when the relationship between variables isn't a straight line but a curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76501788-9e57-44e6-afb3-80c695f44f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 21) How does the intercept in a regression model provide context for the relationship between variables\n",
    ">> by representing the predicted value of the dependent variable when all independent variables are equal to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e32dd6-2fc4-4b8c-89dd-4294157ce3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 22) How can heteroscedasticity be identified in residual plots, and why is it important to address it\n",
    ">> because it invalidates standard error estimates, leading to unreliable t-tests and p-values, making hypothesis testing inaccurate,\n",
    "    though OLS estimators remain unbiased but inefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790937fb-04f8-4de5-a4c0-cce26f5fa243",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 23) What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?\n",
    ">>  your model explains a lot of variance in the training data, but many of the added predictor variables are not statistically significant or relevant,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b47df44-48c3-4d09-ad2f-9efab4f80895",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 24) Why is it important to scale variables in Multiple Linear Regression\n",
    ">>  faster convergence with gradient descent, equalizing feature influence, improving interpretability of coefficients, and ensuring fairness \n",
    "      in regularization techniques, preventing features with larger scales from dominating the model or distance calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3f0cc3-03f2-46c7-92c5-5d846f1639fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 25) How does polynomial regression differ from linear regression\n",
    ">> Linear regression models straight-line (linear) relationships, while polynomial regression models curved (non-linear) relationships\n",
    "by adding polynomial terms (\\(x^{2},x^{3}\\), etc.) to the equation, making it more flexible for complex data patterns but also more prone to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9ce578-174f-4b95-8332-625935de716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 26) What is the general equation for polynomial regression?\n",
    ">> \\(Y=\\beta _{0}+\\beta _{1}X+\\beta _{2}X^{2}+\\dots +\\beta _{n}X^{n}+\\epsilon \\),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e83212-c363-4052-9ecc-6a4a0bacfa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 27) Can polynomial regression be applied to multiple variables\n",
    ">> Yes, polynomial regression can absolutely be applied to multiple variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619c590-f281-42e1-b704-3d6a2a06ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 28) What are the limitations of polynomial regression?\n",
    ">> overfitting (fitting noise, not trend with high degrees), poor extrapolation (unpredictable results outside data range), \n",
    "    and multicollinearity (correlated polynomial terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9bb009-6549-4459-b2eb-f9f2e843657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 29) What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
    ">> use cross-validation (like k-fold) or a separate validation set to check generalization, plot residuals (randomness indicates good fit), \n",
    "     and compare AIC/BIC or Adjusted \\(R^{2}\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df37f111-aa32-487b-8ff1-cf5fc70fee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 30) Why is visualization important in polynomial regression\n",
    ">> for visually identifying non-linear patterns, choosing the right polynomial degree (to avoid overfitting/underfitting),\n",
    " and diagnosing model fit through residual plots, helping to balance the bias-variance tradeoff and ensure the model captures \n",
    "    data trends without fitting noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044ea783-adc9-4554-b801-4c4e0dbdc4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 31) How is polynomial regression implemented in Python?\n",
    ">> using scikit-learn by transforming the input features into higher-degree polynomial terms and then fitting a standard linear\n",
    "    regression model to the transformed data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
